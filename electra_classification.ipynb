{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "electra_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiM1102/Electra_classification_fake_vs_real_news/blob/main/electra_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference tutorial:\n",
        "# https://velog.io/@na2na8/ELECTRA%EB%A1%9C-Binary-Classification#electra-with-pytorch-lightning"
      ],
      "metadata": {
        "id": "0zfy0r0jjBdH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "O9FnNGqjtSPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfecfc0-ab0e-41f9-f484-ce9692fb6926"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 9.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning --quiet\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m_Cni2Xg07r",
        "outputId": "98d395c3-79db-4d40-fbf3-8c49eaac01e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 418 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 19.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 76.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[?25h  Building wheel for pytorch-lightning (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "1.7.0dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOuDtNTCvC7R",
        "outputId": "b7e08064-1859-49bd-b810-a5059293f8df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.17-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=1d66d329ad12a5b3033839ab12c4ff1b698c7852c89412e5189daf393fd7b7c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13KiLc5s1Gej",
        "outputId": "89b7f1b3-ed26-4baa-9428-9eaecbecf5ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import transformers\n",
        "from transformers import ElectraForSequenceClassification, ElectraTokenizer, AdamW\n",
        "\n",
        "device = torch.device(\"cuda\")\n"
      ],
      "metadata": {
        "id": "XgSslOGfgaBW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AyushiM1102/Electra_classification_fake_vs_real_news.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_R1N3WgiH35",
        "outputId": "c2ee81ea-1daa-417a-e6c9-4e14f9445063"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Electra_classification_fake_vs_real_news'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 81 (delta 2), reused 0 (delta 0), pack-reused 75\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip -d /content/Electra_classification_fake_vs_real_news/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aTRK6DSpImU",
        "outputId": "35ed5344-224a-419e-f8a3-41d101936ee5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip\n",
            "  inflating: /content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv  \n",
            "  inflating: /content/Electra_classification_fake_vs_real_news/dataset/__MACOSX/._WELFake_Dataset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview of database\n",
        "# df = pd.read_csv('/content/Electra_classification_fake_vs_real_news/sample_dataset/train.csv', sep=',')\n",
        "datapath = f'/content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv'\n",
        "df = pd.read_csv(datapath, sep=',')\n",
        "df = df.dropna(axis=0)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "7_idswzrWJwK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJhk_cs8p8RO",
        "outputId": "2325838f-00fc-473c-f0c2-11742f88211d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36509\n",
              "0    35028\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(df))\n",
        "val_size = int((2/3)*(len(df) - train_size))\n",
        "test_size = int((1/3)*(len(df) - train_size))\n",
        "train_size, val_size, test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2WXv_TQqk1q",
        "outputId": "3e64f30f-9cbd-4c85-bbe8-21aeea6fca10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50075, 14308, 7154)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size + val_size + test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VA1dmKsWwc9",
        "outputId": "3fb26a6b-e4df-478e-872b-0d5a0ea23467"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71537"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = shuffle(df)"
      ],
      "metadata": {
        "id": "TFO14cYuRX__"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, general_test_dataset  = train_test_split(dataset, train_size=int(0.7 * len(dataset)), test_size=int(0.3 * len(dataset)))"
      ],
      "metadata": {
        "id": "pWGQ9fnURgJE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset, test_dataset = train_test_split(general_test_dataset, train_size=int((2/3) * len(general_test_dataset)), test_size=int((1/3) * len(general_test_dataset)))"
      ],
      "metadata": {
        "id": "V0Z_BML-RkRa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset),len(val_dataset),len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP0_ltmPb2Qv",
        "outputId": "a6c3208c-f591-41a9-c2c9-77411f323094"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50075, 14307, 7153)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/train.csv', index = False)\n",
        "val_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/val.csv', index = False)\n",
        "test_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/test.csv', index = False)"
      ],
      "metadata": {
        "id": "Un3AB9f-qrHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassificationDataset(Dataset) :\n",
        "    def __init__(self, path, sep, doc_col, label_col, max_length, num_workers=1, labels_dict=None) :\n",
        "\n",
        "        self.tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
        "        self.max_length = max_length\n",
        "        self.doc_col = doc_col\n",
        "        self.label_col = label_col\n",
        "\n",
        "        # labels, ex : {True : 1, False : 0}\n",
        "        self.labels_dict = labels_dict\n",
        "\n",
        "        # dataset\n",
        "        df = pd.read_csv(path, sep=sep)\n",
        "        df = df.dropna(axis=0)\n",
        "        df.drop_duplicates(subset=[self.doc_col], inplace=True)\n",
        "        self.dataset = df\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    # Clean text\n",
        "    def cleanse(self, text) :\n",
        "        url_pattern = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "        processed = url_pattern.sub(' ', text)\n",
        "        processed = processed.replace('#', '')\n",
        "        processed = processed.replace('@', '')\n",
        "        processed = processed.strip()\n",
        "        return processed\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        document = self.cleanse(self.dataset[self.doc_col].iloc[idx])\n",
        "        #print(document)\n",
        "        inputs = self.tokenizer(\n",
        "            document,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "\n",
        "        if self.labels_dict :\n",
        "            label = self.labels_dict[self.dataset[self.label_col].iloc[idx]]\n",
        "        else :\n",
        "            label = self.dataset[self.label_col].iloc[idx]\n",
        "\n",
        "        return {\n",
        "            'input_ids' : inputs['input_ids'][0],\n",
        "            'attention_mask' : inputs['attention_mask'][0],\n",
        "            'label' : int(label)\n",
        "        }"
      ],
      "metadata": {
        "id": "qG2NiXYBhWub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassificationDataModule(pl.LightningDataModule) :\n",
        "    def __init__(self, train_path, valid_path, test_path, max_length, batch_size, sep,\n",
        "                doc_col, label_col, num_workers=1, labels_dict=None) :\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = train_path\n",
        "        self.valid_path = valid_path\n",
        "        self.test_path = test_path\n",
        "        self.max_length = max_length\n",
        "        self.doc_col = doc_col\n",
        "        self.label_col = label_col\n",
        "        self.sep = sep\n",
        "        self.num_workers = num_workers\n",
        "        self.labels_dict = labels_dict\n",
        "\n",
        "    def setup(self, stage=None) :\n",
        "        self.set_train = ElectraClassificationDataset(self.train_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        self.set_valid = ElectraClassificationDataset(self.valid_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        self.set_test = ElectraClassificationDataset(self.test_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        \n",
        "\n",
        "    def train_dataloader(self) :\n",
        "        train = DataLoader(self.set_train, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
        "        return train\n",
        "    \n",
        "    def val_dataloader(self) :\n",
        "        val = DataLoader(self.set_valid, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "        return val\n",
        "    \n",
        "    def test_dataloader(self) :\n",
        "        test = DataLoader(self.set_test, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "        return test"
      ],
      "metadata": {
        "id": "dvv9q3-phfSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d\n",
        "# https://huggingface.co/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForSequenceClassification"
      ],
      "metadata": {
        "id": "c1iIOU45h1vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassification(pl.LightningModule) :\n",
        "    def __init__(self, learning_rate) :\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.save_hyperparameters()\n",
        "        self.electra = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\")\n",
        "\n",
        "        self.metric_acc = torchmetrics.Accuracy()\n",
        "        self.metric_f1 = torchmetrics.F1Score(num_classes=2)\n",
        "        self.metric_rec = torchmetrics.Recall(num_classes=2)\n",
        "        self.metric_pre = torchmetrics.Precision(num_classes=2)\n",
        "\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None) :\n",
        "        output = self.electra(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx) :\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward input shape information\n",
        "        * input_ids.shape (batch_size, max_length)\n",
        "        * attention_mask.shape (batch_size, max_length)\n",
        "        * label.shape (batch_size,)\n",
        "        ##########################################################\n",
        "        '''\n",
        "\n",
        "        # change label shape (list -> torch.Tensor((batch_size, 1)))\n",
        "        label = batch['label'].view([-1,1])\n",
        "\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device),\n",
        "                        labels=label.to(device))\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward output shape information\n",
        "        * loss.shape (1,)\n",
        "        * logits.shape (batch_size, config.num_labels=2)\n",
        "        '''\n",
        "        logits = output.logits\n",
        "\n",
        "        loss = output.loss\n",
        "        # loss = self.loss_func(logits.to(device), batch['label'].to(device))\n",
        "\n",
        "        softmax = nn.functional.softmax(logits, dim=1)\n",
        "        preds = softmax.argmax(dim=1)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        \n",
        "        return {\n",
        "            'loss' : loss,\n",
        "            'pred' : preds,\n",
        "            'label' : batch['label']\n",
        "        }\n",
        "\n",
        "    def training_epoch_end(self, outputs, state='train') :\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for i in outputs :\n",
        "            y_true += i['label'].tolist()\n",
        "            y_pred += i['pred'].tolist()\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred)\n",
        "        rec = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        # self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx) :\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward input shape information\n",
        "        * input_ids.shape (batch_size, max_length)\n",
        "        * attention_mask.shape (batch_size, max_length)\n",
        "        ##########################################################\n",
        "        '''\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device))\n",
        "        logits = output.logits\n",
        "        preds = nn.functional.softmax(logits, dim=1).argmax(dim=1)\n",
        "        labels = batch['label']\n",
        "        accuracy = self.metric_acc(preds, labels)\n",
        "        f1 = self.metric_f1(preds, labels)\n",
        "        recall = self.metric_rec(preds, labels)\n",
        "        precision = self.metric_pre(preds, labels)\n",
        "        self.log('val_accuracy', accuracy, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_recall', recall, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_precision', precision, on_epoch=True, prog_bar=True)\n",
        "        return {\n",
        "            'accuracy' : accuracy,\n",
        "            'f1' : f1,\n",
        "            'recall' : recall,\n",
        "            'precision' : precision\n",
        "        }\n",
        "\n",
        "    def validation_epoch_end(self, outputs) :\n",
        "        val_acc = torch.stack([i['accuracy'] for i in outputs]).mean()\n",
        "        val_f1 = torch.stack([i['f1'] for i in outputs]).mean()\n",
        "        val_rec = torch.stack([i['recall'] for i in outputs]).mean()\n",
        "        val_pre = torch.stack([i['precision'] for i in outputs]).mean()\n",
        "        # self.log('val_f1', val_f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_acc', val_acc, on_epoch=True, prog_bar=True)\n",
        "        print(f'val_accuracy : {val_acc}, val_f1 : {val_f1}, val_recall : {val_rec}, val_precision : {val_pre}')\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device))\n",
        "        logits = output.logits\n",
        "        preds = nn.functional.softmax(logits, dim=1).argmax(dim=1)\n",
        "        labels = batch['label']\n",
        "        accuracy = self.metric_acc(preds, labels)\n",
        "        f1 = self.metric_f1(preds, labels)\n",
        "        recall = self.metric_rec(preds, labels)\n",
        "        precision = self.metric_pre(preds, labels)\n",
        "        self.log('test_accuracy', accuracy, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_recall', recall, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_precision', precision, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return {\n",
        "            'accuracy' : accuracy,\n",
        "            'f1' : f1,\n",
        "            'recall' : recall,\n",
        "            'precision' : precision\n",
        "        }\n",
        "\n",
        "\n",
        "    def test_end(self, outputs):\n",
        "        test_acc = torch.stack([i['accuracy'] for i in outputs]).mean()\n",
        "        test_f1 = torch.stack([i['f1'] for i in outputs]).mean()\n",
        "        test_rec = torch.stack([i['recall'] for i in outputs]).mean()\n",
        "        test_pre = torch.stack([i['precision'] for i in outputs]).mean()\n",
        "        # self.log('val_f1', val_f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_acc', val_acc, on_epoch=True, prog_bar=True)\n",
        "        print(f'test_accuracy : {test_acc}, test_f1 : {test_f1}, test_recall : {test_rec}, test_precision : {test_pre}')\n",
        "        \n",
        "\n",
        "    # def test_epoch_end(self, outputs):\n",
        "    #     all_preds, all_labels = [], []\n",
        "    #     for output in outputs:\n",
        "    #         probs = list(output['logits'].cpu().detach().numpy()) # predicted values\n",
        "    #         labels = list(output['labels'].flatten().cpu().detach().numpy())\n",
        "    #         all_preds.extend(probs)\n",
        "    #         all_labels.extend(labels)\n",
        "\n",
        "    #     # you can calculate R2 here or save results as file\n",
        "    #     r2 = ...\n",
        "    \n",
        "    # def predict_step(self, test_batch):\n",
        "    #   x, y = test_batch\n",
        "    #   logits = self.forward(x)\n",
        "    #   return {'logits': logits, 'labels':y}\n",
        "\n",
        "    def configure_optimizers(self) :\n",
        "        optimizer = torch.optim.AdamW(self.electra.parameters(), lr=self.learning_rate)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "        \n",
        "        return {\n",
        "            'optimizer' : optimizer,\n",
        "            'lr_scheduler' : lr_scheduler\n",
        "        }"
      ],
      "metadata": {
        "id": "dr1NkLgFh-oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "lfzzLTeoOn0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main to train the model\n",
        "\n",
        "# Initialize WandB \n",
        "wandb_logger = WandbLogger(project='Electra Classification', \n",
        "                           log_model='all')\n",
        "model = ElectraClassification(learning_rate=0.0001)\n",
        "\n",
        "wandb.watch(model)\n",
        "\n",
        "dm = ElectraClassificationDataModule(batch_size=8, train_path='/content/Electra_classification_fake_vs_real_news/dataset/train.csv', valid_path='/content/Electra_classification_fake_vs_real_news/dataset/val.csv',\n",
        "                                     test_path='/content/Electra_classification_fake_vs_real_news/dataset/test.csv',\n",
        "                                max_length=512, sep=',', doc_col='text', label_col='label', num_workers=1)\n",
        "dm.setup()\n",
        "train_dataset = dm.train_dataloader()\n",
        "valid_dataset = dm.val_dataloader()\n",
        "\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_accuracy',\n",
        "                                                dirpath='./sample_electra_binary_nsmc_chpt',\n",
        "                                                filename='ELECTRA/{epoch:02d}-{val_accuracy:.3f}',\n",
        "                                                verbose=True,\n",
        "                                                save_last=True,\n",
        "                                                mode='max',\n",
        "                                                save_top_k=-1,\n",
        "                                                )\n",
        "\n",
        "tb_logger = pl_loggers.TensorBoardLogger(os.path.join('./sample_electra_binary_nsmc_chpt', 'tb_logs'))\n",
        "\n",
        "lr_logger = pl.callbacks.LearningRateMonitor()\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    default_root_dir='./sample_electra_binary_nsmc_chpt/checkpoints',\n",
        "    logger = wandb_logger,\n",
        "    callbacks = [checkpoint_callback, lr_logger],\n",
        "    max_epochs=5,\n",
        "    gpus=1)\n",
        "\n",
        "trainer.fit(model, train_dataset, valid_dataset)"
      ],
      "metadata": {
        "id": "a4e9tpVeiHXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dm.test_dataloader()\n",
        "# trainer.test(dataloaders=test_dataset)\n",
        "trainer.test(ckpt_path=None)"
      ],
      "metadata": {
        "id": "B_l8d61NfgCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "o1M5OQE830Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code below this line is extraneous. "
      ],
      "metadata": {
        "id": "t-1I-LQG4AaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electra = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\")\n",
        "\n",
        "# Check parameters\n",
        "dm = ElectraClassificationDataModule(batch_size=8, train_path='/content/Electra_classification_fake_vs_real_news/sample_dataset/train.csv', valid_path='/content/Electra_classification_fake_vs_real_news/sample_dataset/val.csv',\n",
        "                                    max_length=256, sep=',', doc_col='Tweet', label_col='is_retweet', num_workers=1)\n",
        "\n",
        "dm.setup()\n",
        "\n",
        "t = dm.train_dataloader()\n",
        "\n",
        "print(t)\n",
        "for idx, data in enumerate(t):\n",
        "    print(idx, data['input_ids'].shape, data['attention_mask'].shape, data['label'].shape)\n",
        "\n",
        "# Concatenate the batches ?? ********* PENDING *********** HOW TO DO THIS ?? \n",
        "#idx, data = enumerate(t)\n",
        "\n",
        "v = dm.val_dataloader()\n",
        "\n",
        "for idx, data in enumerate(v) :\n",
        "  print(idx, data['input_ids'].shape, data['attention_mask'].shape, data['label'].shape)\n",
        "  # print(idx, data['input_ids'], data['attention_mask'], data['label'])\n",
        "\n",
        "  output = electra.forward(data['input_ids'], attention_mask=data['attention_mask'], labels=data['label'].view([-1,1]))\n",
        "\n",
        "  print(\"This is the loss\")\n",
        "  print(output.loss)\n",
        "  # print(output.loss.shape)\n",
        "  # print(output.logits)\n",
        "  print(output.logits.shape)\n",
        "\n",
        "  softmax = nn.functional.softmax(output.logits, dim=1)\n",
        "  print('softmax', softmax)\n",
        "  pred = softmax.argmax(dim=1)\n",
        "  print('pred', pred)\n",
        "\n",
        "  y_true = data['label'].tolist()\n",
        "  y_pred = pred.tolist()\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred)\n",
        "rec = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'acc : {acc}, prec : {prec}, rec : {rec}, f1 : {f1}')\n"
      ],
      "metadata": {
        "id": "hFQuspRvhpX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}