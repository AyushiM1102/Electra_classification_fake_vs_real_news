{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "electra_classification_metric.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78ffcb12982c462484d52931bf2eebff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6753e06d2c3d440d90181c11f1d0b5ea",
              "IPY_MODEL_01f009e403ce405e876b8933820f171d",
              "IPY_MODEL_13c89d43739945559ff78ee36accf578"
            ],
            "layout": "IPY_MODEL_616e46776be44d1fb0a4919a58385e6a"
          }
        },
        "6753e06d2c3d440d90181c11f1d0b5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e4542f53d0429397b170203efccc8b",
            "placeholder": "​",
            "style": "IPY_MODEL_2dc8f463910d42c1991b5c46d8f4b2b1",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "01f009e403ce405e876b8933820f171d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a7cd1bb9f34b7e9355243329978a58",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc6aa204b28c498f9374e09c56abdd3b",
            "value": 2
          }
        },
        "13c89d43739945559ff78ee36accf578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4970c6e2ac8c4e7d88d706f97b8176bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0a96b1d7dcf249d6b2fa8850fcb6cd68",
            "value": " 2/2 [00:00&lt;00:00, 10.59it/s]"
          }
        },
        "616e46776be44d1fb0a4919a58385e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a3e4542f53d0429397b170203efccc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc8f463910d42c1991b5c46d8f4b2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66a7cd1bb9f34b7e9355243329978a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6aa204b28c498f9374e09c56abdd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4970c6e2ac8c4e7d88d706f97b8176bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a96b1d7dcf249d6b2fa8850fcb6cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8c41fd017bc45069ec6fd67d5447741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29816b98f27943d98cba02e1500fc3a8",
              "IPY_MODEL_646c03a15ea54e688b4174cf7cd31592",
              "IPY_MODEL_5e127cd7522b43a195cf2cb5c3d918fb"
            ],
            "layout": "IPY_MODEL_f72734e410524a2eadac63f26304c1e2"
          }
        },
        "29816b98f27943d98cba02e1500fc3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a93b7c4f8b4473fb9ea303723fa2e87",
            "placeholder": "​",
            "style": "IPY_MODEL_f2a5cb5a302f4d2e89f9419bb9e05f15",
            "value": "Epoch 0:  11%"
          }
        },
        "646c03a15ea54e688b4174cf7cd31592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e335cd86c2d74a3da3b7b3f0792d0eb8",
            "max": 7366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de0d748f66fc459f8d76368ccd2831fb",
            "value": 840
          }
        },
        "5e127cd7522b43a195cf2cb5c3d918fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff614f5af6f4cf398c0f0d7ff6ee3f1",
            "placeholder": "​",
            "style": "IPY_MODEL_ae1be6fa7a4d490e83b363a795c4588e",
            "value": " 840/7366 [02:05&lt;16:16,  6.68it/s, loss=0.057, v_num=1y85, train_loss=0.0046]"
          }
        },
        "f72734e410524a2eadac63f26304c1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6a93b7c4f8b4473fb9ea303723fa2e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a5cb5a302f4d2e89f9419bb9e05f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e335cd86c2d74a3da3b7b3f0792d0eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0d748f66fc459f8d76368ccd2831fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ff614f5af6f4cf398c0f0d7ff6ee3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae1be6fa7a4d490e83b363a795c4588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiM1102/Electra_classification_fake_vs_real_news/blob/main/electra_classification_metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference tutorial:\n",
        "# https://velog.io/@na2na8/ELECTRA%EB%A1%9C-Binary-Classification#electra-with-pytorch-lightning"
      ],
      "metadata": {
        "id": "0zfy0r0jjBdH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "O9FnNGqjtSPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning --quiet\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m_Cni2Xg07r",
        "outputId": "140676e5-6402-41c8-a07b-7343626276e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "1.7.0dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOuDtNTCvC7R",
        "outputId": "3793d870-aff3-4499-c0d0-860889e21fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.17)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13KiLc5s1Gej",
        "outputId": "df050e98-ba0c-4fe3-c2ff-7c7926076a21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamcheyre\u001b[0m (\u001b[33mninja-women\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import transformers\n",
        "from transformers import ElectraForSequenceClassification, ElectraTokenizer, AdamW\n",
        "\n",
        "device = torch.device(\"cuda\")\n"
      ],
      "metadata": {
        "id": "XgSslOGfgaBW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AyushiM1102/Electra_classification_fake_vs_real_news.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_R1N3WgiH35",
        "outputId": "1a4613bf-5969-47a5-a8ef-672403cbf378"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Electra_classification_fake_vs_real_news' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip -d /content/Electra_classification_fake_vs_real_news/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aTRK6DSpImU",
        "outputId": "551fa9f6-2edc-4461-9a7f-951b87383144"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip\n",
            "replace /content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/Electra_classification_fake_vs_real_news/dataset/__MACOSX/._WELFake_Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview of database\n",
        "# df = pd.read_csv('/content/Electra_classification_fake_vs_real_news/sample_dataset/train.csv', sep=',')\n",
        "datapath = f'/content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv'\n",
        "df = pd.read_csv(datapath, sep=',')\n",
        "df = df.dropna(axis=0)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "7_idswzrWJwK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJhk_cs8p8RO",
        "outputId": "70561d4b-d3f2-459b-c562-369c7ae10c54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36509\n",
              "0    35028\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(df))\n",
        "val_size = int((2/3)*(len(df) - train_size))\n",
        "test_size = int((1/3)*(len(df) - train_size))\n",
        "train_size, val_size, test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2WXv_TQqk1q",
        "outputId": "4c4a42ee-a13e-43d3-ac22-24981ebabcbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50075, 14308, 7154)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size + val_size + test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VA1dmKsWwc9",
        "outputId": "d0d765fa-31ff-402d-c714-9266195edb17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71537"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = shuffle(df)"
      ],
      "metadata": {
        "id": "TFO14cYuRX__"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, general_test_dataset  = train_test_split(dataset, train_size=int(0.7 * len(dataset)), test_size=int(0.3 * len(dataset)))"
      ],
      "metadata": {
        "id": "pWGQ9fnURgJE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset, test_dataset = train_test_split(general_test_dataset, train_size=int((2/3) * len(general_test_dataset)), test_size=int((1/3) * len(general_test_dataset)))"
      ],
      "metadata": {
        "id": "V0Z_BML-RkRa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset),len(val_dataset),len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP0_ltmPb2Qv",
        "outputId": "c5a56995-a9a0-4121-8ba8-c70e976e5ec8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50075, 14307, 7153)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/train.csv', index = False)\n",
        "val_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/val.csv', index = False)\n",
        "test_dataset.to_csv('/content/Electra_classification_fake_vs_real_news/dataset/test.csv', index = False)"
      ],
      "metadata": {
        "id": "Un3AB9f-qrHS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassificationDataset(Dataset) :\n",
        "    def __init__(self, path, sep, doc_col, label_col, max_length, num_workers=1, labels_dict=None) :\n",
        "\n",
        "        self.tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
        "        self.max_length = max_length\n",
        "        self.doc_col = doc_col\n",
        "        self.label_col = label_col\n",
        "\n",
        "        # labels, ex : {True : 1, False : 0}\n",
        "        self.labels_dict = labels_dict\n",
        "\n",
        "        # dataset\n",
        "        df = pd.read_csv(path, sep=sep)\n",
        "        df = df.dropna(axis=0)\n",
        "        df.drop_duplicates(subset=[self.doc_col], inplace=True)\n",
        "        self.dataset = df\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    # Clean text\n",
        "    def cleanse(self, text) :\n",
        "        url_pattern = re.compile(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "        processed = url_pattern.sub(' ', text)\n",
        "        processed = processed.replace('#', '')\n",
        "        processed = processed.replace('@', '')\n",
        "        processed = processed.strip()\n",
        "        return processed\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        document = self.cleanse(self.dataset[self.doc_col].iloc[idx])\n",
        "        #print(document)\n",
        "        inputs = self.tokenizer(\n",
        "            document,\n",
        "            return_tensors='pt',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "\n",
        "        if self.labels_dict :\n",
        "            label = self.labels_dict[self.dataset[self.label_col].iloc[idx]]\n",
        "        else :\n",
        "            label = self.dataset[self.label_col].iloc[idx]\n",
        "\n",
        "        return {\n",
        "            'input_ids' : inputs['input_ids'][0],\n",
        "            'attention_mask' : inputs['attention_mask'][0],\n",
        "            'label' : int(label)\n",
        "        }"
      ],
      "metadata": {
        "id": "qG2NiXYBhWub"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassificationDataModule(pl.LightningDataModule) :\n",
        "    def __init__(self, train_path, valid_path, test_path, max_length, batch_size, sep,\n",
        "                doc_col, label_col, num_workers=1, labels_dict=None) :\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = train_path\n",
        "        self.valid_path = valid_path\n",
        "        self.test_path = test_path\n",
        "        self.max_length = max_length\n",
        "        self.doc_col = doc_col\n",
        "        self.label_col = label_col\n",
        "        self.sep = sep\n",
        "        self.num_workers = num_workers\n",
        "        self.labels_dict = labels_dict\n",
        "\n",
        "    def setup(self, stage=None) :\n",
        "      \n",
        "        self.set_train = ElectraClassificationDataset(self.train_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        \n",
        "        self.set_valid = ElectraClassificationDataset(self.valid_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        \n",
        "        self.set_test = ElectraClassificationDataset(self.test_path, sep=self.sep,\n",
        "                                            doc_col=self.doc_col, label_col=self.label_col,\n",
        "                                            max_length = self.max_length, labels_dict=self.labels_dict)\n",
        "        \n",
        "\n",
        "    def train_dataloader(self) :\n",
        "        train = DataLoader(self.set_train, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
        "        return train\n",
        "    \n",
        "    def val_dataloader(self) :\n",
        "        val = DataLoader(self.set_valid, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "        return val\n",
        "    \n",
        "    def test_dataloader(self) :\n",
        "        test = DataLoader(self.set_test, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
        "        return test"
      ],
      "metadata": {
        "id": "dvv9q3-phfSS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d\n",
        "# https://huggingface.co/docs/transformers/v4.15.0/en/model_doc/electra#transformers.ElectraForSequenceClassification"
      ],
      "metadata": {
        "id": "c1iIOU45h1vi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraClassification(pl.LightningModule) :\n",
        "    def __init__(self, learning_rate) :\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.save_hyperparameters()\n",
        "        self.electra = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\")\n",
        "\n",
        "        self.metric_acc = torchmetrics.Accuracy()\n",
        "        self.metric_f1 = torchmetrics.F1Score(num_classes=2)\n",
        "        self.metric_rec = torchmetrics.Recall(num_classes=2)\n",
        "        self.metric_pre = torchmetrics.Precision(num_classes=2)\n",
        "\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None) :\n",
        "        output = self.electra(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx) :\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward input shape information\n",
        "        * input_ids.shape (batch_size, max_length)\n",
        "        * attention_mask.shape (batch_size, max_length)\n",
        "        * label.shape (batch_size,)\n",
        "        ##########################################################\n",
        "        '''\n",
        "\n",
        "        # change label shape (list -> torch.Tensor((batch_size, 1)))\n",
        "        label = batch['label'].view([-1,1])\n",
        "\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device),\n",
        "                        labels=label.to(device))\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward output shape information\n",
        "        * loss.shape (1,)\n",
        "        * logits.shape (batch_size, config.num_labels=2)\n",
        "        '''\n",
        "        logits = output.logits\n",
        "\n",
        "        loss = output.loss\n",
        "        # loss = self.loss_func(logits.to(device), batch['label'].to(device))\n",
        "\n",
        "        softmax = nn.functional.softmax(logits, dim=1)\n",
        "        preds = softmax.argmax(dim=1)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        \n",
        "        return {\n",
        "            'loss' : loss,\n",
        "            'pred' : preds,\n",
        "            'label' : batch['label']\n",
        "        }\n",
        "\n",
        "    def training_epoch_end(self, outputs, state='train') :\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for i in outputs :\n",
        "            y_true += i['label'].tolist()\n",
        "            y_pred += i['pred'].tolist()\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred)\n",
        "        rec = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "        # Metrics for training using Numpy\n",
        "        # print(f\"Type of y_pred is {type(y_pred)}\")\n",
        "\n",
        "        train_label = np.array(y_pred)\n",
        "        real_label = np.array(y_true)\n",
        "\n",
        "        TP = ((real_label == 1) & (train_label == 1)).sum()\n",
        "        FP = ((real_label == 1) & (train_label == 0)).sum()\n",
        "        FN = ((real_label == 0) & (train_label == 1)).sum()\n",
        "        acc_sum = (real_label == train_label).sum().item()\n",
        "\n",
        "        acc_train = acc_sum / len(y_pred)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        F1_score = TP / (TP + 0.5*(FN+FP))\n",
        "\n",
        "        # self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n",
        "        # self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n",
        "        #print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Acc: {acc_train}, Prec: {precision}, Rec: {recall}, F1: {F1_score}')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx) :\n",
        "        '''\n",
        "        ##########################################################\n",
        "        electra forward input shape information\n",
        "        * input_ids.shape (batch_size, max_length)\n",
        "        * attention_mask.shape (batch_size, max_length)\n",
        "        ##########################################################\n",
        "        '''\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device))\n",
        "        logits = output.logits\n",
        "        preds = nn.functional.softmax(logits, dim=1).argmax(dim=1)\n",
        "        labels = batch['label']\n",
        "\n",
        "        accuracy = self.metric_acc(preds, labels)\n",
        "        f1 = self.metric_f1(preds, labels)\n",
        "        rec = self.metric_rec(preds, labels)\n",
        "        prec = self.metric_pre(preds, labels)\n",
        "\n",
        "        # Metrics for validation using Numpy\n",
        "        val_label = preds.cpu().detach().numpy()\n",
        "        real_label = labels.cpu().detach().numpy()\n",
        "\n",
        "        TP = ((real_label == 1) & (val_label == 1)).sum()\n",
        "        FP = ((real_label == 1) & (val_label == 0)).sum()\n",
        "        FN = ((real_label == 0) & (val_label == 1)).sum()\n",
        "        acc_sum = (real_label == val_label).sum().item()\n",
        "\n",
        "        acc_val = acc_sum / len(val_label)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        F1_score = TP / (TP + 0.5*(FN+FP))\n",
        "\n",
        "        # self.log('val_accuracy', accuracy, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_recall', rec, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_precision', prec, on_epoch=True, prog_bar=True)\n",
        "        \n",
        "        # return {\n",
        "        #     'accuracy' : accuracy,\n",
        "        #     'f1' : f1,\n",
        "        #     'recall' : recall,\n",
        "        #     'precision' : precision\n",
        "        # }\n",
        "\n",
        "        if str(acc_val) != 'nan' and str(precision) != 'nan' and str(recall) != 'nan' and str(F1_score) != 'nan':\n",
        "\n",
        "          self.log('val_accuracy', acc_val, on_epoch=True, prog_bar=True)\n",
        "          self.log('val_f1', F1_score, on_epoch=True, prog_bar=True)\n",
        "          self.log('val_recall', recall, on_epoch=True, prog_bar=True)\n",
        "          self.log('val_precision', precision, on_epoch=True, prog_bar=True)\n",
        "\n",
        "          #print(f'This is one step: val_accuracy : {acc_val}, val_f1 : {F1_score}, val_recall : {recall}, val_precision : {precision}')\n",
        "\n",
        "          return {\n",
        "              'accuracy' : acc_val,\n",
        "              'f1' : F1_score,\n",
        "              'recall' : recall,\n",
        "              'precision' : precision\n",
        "          }\n",
        "\n",
        "    def validation_epoch_end(self, outputs) :\n",
        "        # val_acc = torch.stack([i['accuracy'] for i in outputs]).mean()\n",
        "        # val_f1 = torch.stack([i['f1'] for i in outputs]).mean()\n",
        "        # val_rec = torch.stack([i['recall'] for i in outputs]).mean()\n",
        "        # val_pre = torch.stack([i['precision'] for i in outputs]).mean()\n",
        "\n",
        "        print(f\"This is output in validation epoch end {outputs}\")\n",
        "        val_acc = []\n",
        "        val_f1 = []\n",
        "        val_rec = []\n",
        "        val_pre = []\n",
        "\n",
        "        for item in outputs:\n",
        "          val_acc.append(item['accuracy'])\n",
        "          val_f1.append(item['f1'])\n",
        "          val_rec.append(item['recall'])\n",
        "          val_pre.append(item['precision'])\n",
        "\n",
        "        # val_acc = outputs['accuracy'].mean()\n",
        "        # val_f1 = outputs['f1'].mean()\n",
        "        # val_rec = outputs['recall'].mean()\n",
        "        # val_pre = outputs['precision'].mean()\n",
        "\n",
        "        # self.log('val_f1', val_f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_acc', val_acc, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        # print(f'val_accuracy : {val_acc}, val_f1 : {val_f1}, val_recall : {val_rec}, val_precision : {val_pre}')\n",
        "        \n",
        "        print(f'val_accuracy : {sum(val_acc)/len(val_acc)}, val_f1 : {sum(val_f1)/len(val_f1)}, val_recall : {sum(val_rec)/len(val_rec)}, val_precision : {sum(val_pre)/len(val_pre)}')\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        output = self(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device))\n",
        "        logits = output.logits\n",
        "        preds = nn.functional.softmax(logits, dim=1).argmax(dim=1)\n",
        "        labels = batch['label']\n",
        "\n",
        "        accuracy = self.metric_acc(preds, labels)\n",
        "        f1 = self.metric_f1(preds, labels)\n",
        "        recall = self.metric_rec(preds, labels)\n",
        "        precision = self.metric_pre(preds, labels)\n",
        "\n",
        "        # Metrics for test using Numpy\n",
        "        test_label = preds.cpu().detach().numpy()\n",
        "        real_label = labels.cpu().detach().numpy()\n",
        "\n",
        "        TP = ((real_label == 1) & (test_label == 1)).sum()\n",
        "        FP = ((real_label == 1) & (test_label == 0)).sum()\n",
        "        FN = ((real_label == 0) & (test_label == 1)).sum()\n",
        "        acc_sum = (real_label == test_label).sum().item()\n",
        "\n",
        "        acc_test = acc_sum / len(test_label)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        F1_score = TP / (TP + 0.5*(FN+FP))\n",
        "\n",
        "        # self.log('test_accuracy', accuracy, on_epoch=True, prog_bar=True)\n",
        "        # self.log('test_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('test_recall', recall, on_epoch=True, prog_bar=True)\n",
        "        # self.log('test_precision', precision, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        # return {\n",
        "        #     'accuracy' : accuracy,\n",
        "        #     'f1' : f1,\n",
        "        #     'recall' : recall,\n",
        "        #     'precision' : precision\n",
        "        # }\n",
        "\n",
        "        if str(acc_test) != 'nan' and str(precision) != 'nan' and str(recall) != 'nan' and str(F1_score) != 'nan':\n",
        "\n",
        "          self.log('test_accuracy', acc_test, on_epoch=True, prog_bar=True)\n",
        "          self.log('test_f1', F1_score, on_epoch=True, prog_bar=True)\n",
        "          self.log('test_recall', recall, on_epoch=True, prog_bar=True)\n",
        "          self.log('test_precision', precision, on_epoch=True, prog_bar=True)\n",
        "\n",
        "          #print(f'This is one step: val_accuracy : {acc_val}, val_f1 : {F1_score}, val_recall : {recall}, val_precision : {precision}')\n",
        "\n",
        "          return {\n",
        "              'accuracy' : acc_test,\n",
        "              'f1' : F1_score,\n",
        "              'recall' : recall,\n",
        "              'precision' : precision\n",
        "          }\n",
        "\n",
        "\n",
        "    def test_end(self, outputs):\n",
        "        # test_acc = torch.stack([i['accuracy'] for i in outputs]).mean()\n",
        "        # test_f1 = torch.stack([i['f1'] for i in outputs]).mean()\n",
        "        # test_rec = torch.stack([i['recall'] for i in outputs]).mean()\n",
        "        # test_pre = torch.stack([i['precision'] for i in outputs]).mean()\n",
        "        # self.log('val_f1', val_f1, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_acc', val_acc, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        test_acc = []\n",
        "        test_f1 = []\n",
        "        test_rec = []\n",
        "        test_pre = []\n",
        "\n",
        "        for item in outputs:\n",
        "          test_acc.append(item['accuracy'])\n",
        "          test_f1.append(item['f1'])\n",
        "          test_rec.append(item['recall'])\n",
        "          test_pre.append(item['precision'])\n",
        "\n",
        "        # print(f'test_accuracy : {test_acc}, test_f1 : {test_f1}, test_recall : {test_rec}, test_precision : {test_pre}')\n",
        "        print(f'test_accuracy : {sum(test_acc)/len(test_acc)}, test_f1 : {sum(test_f1)/len(test_f1)}, test_recall : {sum(test_rec)/len(test_rec)}, test_precision : {sum(test_pre)/len(test_pre)}')\n",
        "\n",
        "        \n",
        "\n",
        "    # def test_epoch_end(self, outputs):\n",
        "    #     all_preds, all_labels = [], []\n",
        "    #     for output in outputs:\n",
        "    #         probs = list(output['logits'].cpu().detach().numpy()) # predicted values\n",
        "    #         labels = list(output['labels'].flatten().cpu().detach().numpy())\n",
        "    #         all_preds.extend(probs)\n",
        "    #         all_labels.extend(labels)\n",
        "\n",
        "    #     # you can calculate R2 here or save results as file\n",
        "    #     r2 = ...\n",
        "    \n",
        "    # def predict_step(self, test_batch):\n",
        "    #   x, y = test_batch\n",
        "    #   logits = self.forward(x)\n",
        "    #   return {'logits': logits, 'labels':y}\n",
        "\n",
        "    def configure_optimizers(self) :\n",
        "        optimizer = torch.optim.AdamW(self.electra.parameters(), lr=self.learning_rate)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "        \n",
        "        return {\n",
        "            'optimizer' : optimizer,\n",
        "            'lr_scheduler' : lr_scheduler\n",
        "        }"
      ],
      "metadata": {
        "id": "dr1NkLgFh-oR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main to train the model\n",
        "\n",
        "# Initialize WandB \n",
        "wandb_logger = WandbLogger(project='Electra Classification', \n",
        "                           log_model='all')\n",
        "model = ElectraClassification(learning_rate=0.0001)\n",
        "\n",
        "wandb.watch(model)\n",
        "\n",
        "dm = ElectraClassificationDataModule(batch_size=8, train_path='/content/Electra_classification_fake_vs_real_news/dataset/train.csv', valid_path='/content/Electra_classification_fake_vs_real_news/dataset/val.csv',\n",
        "                                     test_path='/content/Electra_classification_fake_vs_real_news/dataset/test.csv',\n",
        "                                max_length=512, sep=',', doc_col='text', label_col='label', num_workers=1)\n",
        "dm.setup()\n",
        "train_dataset = dm.train_dataloader()\n",
        "valid_dataset = dm.val_dataloader()\n",
        "\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_accuracy',\n",
        "                                                dirpath='./sample_electra_binary_nsmc_chpt',\n",
        "                                                filename='ELECTRA/{epoch:02d}-{val_accuracy:.3f}',\n",
        "                                                verbose=True,\n",
        "                                                save_last=True,\n",
        "                                                mode='max',\n",
        "                                                save_top_k=-1,\n",
        "                                                )\n",
        "\n",
        "tb_logger = pl_loggers.TensorBoardLogger(os.path.join('./sample_electra_binary_nsmc_chpt', 'tb_logs'))\n",
        "\n",
        "lr_logger = pl.callbacks.LearningRateMonitor()\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    default_root_dir='./sample_electra_binary_nsmc_chpt/checkpoints',\n",
        "    logger = wandb_logger,\n",
        "    callbacks = [checkpoint_callback, lr_logger],\n",
        "    max_epochs=5,\n",
        "    gpus=1)\n",
        "\n",
        "trainer.fit(model, train_dataset, valid_dataset)"
      ],
      "metadata": {
        "id": "a4e9tpVeiHXg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896,
          "referenced_widgets": [
            "78ffcb12982c462484d52931bf2eebff",
            "6753e06d2c3d440d90181c11f1d0b5ea",
            "01f009e403ce405e876b8933820f171d",
            "13c89d43739945559ff78ee36accf578",
            "616e46776be44d1fb0a4919a58385e6a",
            "a3e4542f53d0429397b170203efccc8b",
            "2dc8f463910d42c1991b5c46d8f4b2b1",
            "66a7cd1bb9f34b7e9355243329978a58",
            "dc6aa204b28c498f9374e09c56abdd3b",
            "4970c6e2ac8c4e7d88d706f97b8176bb",
            "0a96b1d7dcf249d6b2fa8850fcb6cd68",
            "b8c41fd017bc45069ec6fd67d5447741",
            "29816b98f27943d98cba02e1500fc3a8",
            "646c03a15ea54e688b4174cf7cd31592",
            "5e127cd7522b43a195cf2cb5c3d918fb",
            "f72734e410524a2eadac63f26304c1e2",
            "6a93b7c4f8b4473fb9ea303723fa2e87",
            "f2a5cb5a302f4d2e89f9419bb9e05f15",
            "e335cd86c2d74a3da3b7b3f0792d0eb8",
            "de0d748f66fc459f8d76368ccd2831fb",
            "0ff614f5af6f4cf398c0f0d7ff6ee3f1",
            "ae1be6fa7a4d490e83b363a795c4588e"
          ]
        },
        "outputId": "d77fd285-1325-4c17-9383-4cba5eb8494b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/wandb.py:348: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n",
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:430: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /content/sample_electra_binary_nsmc_chpt exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type                             | Params\n",
            "----------------------------------------------------------------\n",
            "0 | electra    | ElectraForSequenceClassification | 13.5 M\n",
            "1 | metric_acc | Accuracy                         | 0     \n",
            "2 | metric_f1  | F1Score                          | 0     \n",
            "3 | metric_rec | Recall                           | 0     \n",
            "4 | metric_pre | Precision                        | 0     \n",
            "5 | loss_func  | CrossEntropyLoss                 | 0     \n",
            "----------------------------------------------------------------\n",
            "13.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.5 M    Total params\n",
            "54.197    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78ffcb12982c462484d52931bf2eebff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is output in validation epoch end [{'accuracy': 0.625, 'f1': 0.5714285714285714, 'recall': 0.6666666666666666, 'precision': 0.5}, {'accuracy': 0.375, 'f1': 0.4444444444444444, 'recall': 0.3333333333333333, 'precision': 0.6666666666666666}]\n",
            "val_accuracy : 0.5, val_f1 : 0.5079365079365079, val_recall : 0.5, val_precision : 0.5833333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
            "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
            "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
            "                achieved and we recommend setting this to `False`.\n",
            "                We provide an checking function\n",
            "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
            "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
            "                default for now) or if `full_state_update=False` can be used safely.\n",
            "                \n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  category=PossibleUserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8c41fd017bc45069ec6fd67d5447741"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = dm.test_dataloader()\n",
        "# trainer.test(dataloaders=test_dataset)\n",
        "trainer.test(ckpt_path=None)"
      ],
      "metadata": {
        "id": "B_l8d61NfgCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "o1M5OQE830Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code below this line is extraneous. "
      ],
      "metadata": {
        "id": "t-1I-LQG4AaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electra = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\")\n",
        "\n",
        "# Check parameters\n",
        "dm = ElectraClassificationDataModule(batch_size=8, train_path='/content/Electra_classification_fake_vs_real_news/sample_dataset/train.csv', valid_path='/content/Electra_classification_fake_vs_real_news/sample_dataset/val.csv',\n",
        "                                    max_length=256, sep=',', doc_col='Tweet', label_col='is_retweet', num_workers=1)\n",
        "\n",
        "dm.setup()\n",
        "\n",
        "t = dm.train_dataloader()\n",
        "\n",
        "print(t)\n",
        "for idx, data in enumerate(t):\n",
        "    print(idx, data['input_ids'].shape, data['attention_mask'].shape, data['label'].shape)\n",
        "\n",
        "# Concatenate the batches ?? ********* PENDING *********** HOW TO DO THIS ?? \n",
        "#idx, data = enumerate(t)\n",
        "\n",
        "v = dm.val_dataloader()\n",
        "\n",
        "for idx, data in enumerate(v) :\n",
        "  print(idx, data['input_ids'].shape, data['attention_mask'].shape, data['label'].shape)\n",
        "  # print(idx, data['input_ids'], data['attention_mask'], data['label'])\n",
        "\n",
        "  output = electra.forward(data['input_ids'], attention_mask=data['attention_mask'], labels=data['label'].view([-1,1]))\n",
        "\n",
        "  print(\"This is the loss\")\n",
        "  print(output.loss)\n",
        "  # print(output.loss.shape)\n",
        "  # print(output.logits)\n",
        "  print(output.logits.shape)\n",
        "\n",
        "  softmax = nn.functional.softmax(output.logits, dim=1)\n",
        "  print('softmax', softmax)\n",
        "  pred = softmax.argmax(dim=1)\n",
        "  print('pred', pred)\n",
        "\n",
        "  y_true = data['label'].tolist()\n",
        "  y_pred = pred.tolist()\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred)\n",
        "rec = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'acc : {acc}, prec : {prec}, rec : {rec}, f1 : {f1}')\n"
      ],
      "metadata": {
        "id": "hFQuspRvhpX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}