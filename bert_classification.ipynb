{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPhFounEqkrxJ0AhGDCZDPw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiM1102/Electra_classification_fake_vs_real_news/blob/main/bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "E4nAX4XR96s4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA6ODcuRJRtI",
        "outputId": "5f1cbf45-8b74-4d18-8e12-739b8387e36c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "D2AZCRrX-SCk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AyushiM1102/Electra_classification_fake_vs_real_news.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SRfNd4UhdHy",
        "outputId": "e7c559b3-ec6e-4066-88d9-9e034b71748c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Electra_classification_fake_vs_real_news' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip -d /content/Electra_classification_fake_vs_real_news/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU7HqRspetX5",
        "outputId": "addd398b-ffb0-4ce7-e277-682e12f13d7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip\n",
            "replace /content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/Electra_classification_fake_vs_real_news/dataset/__MACOSX/._WELFake_Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = f'/content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv'\n",
        "df = pd.read_csv(datapath)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tbYvbtie-SAh",
        "outputId": "1b4e3ea3-18be-4472-b78d-40d309c7bdf0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
              "1           1                                                NaN   \n",
              "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
              "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
              "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
              "\n",
              "                                                text  label  \n",
              "0  No comment is expected from Barack Obama Membe...      1  \n",
              "1     Did they post their votes for Hillary already?      1  \n",
              "2   Now, most of the demonstrators gathered last ...      1  \n",
              "3  A dozen politically active pastors came here f...      0  \n",
              "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47c96310-2bbe-4349-8101-00cdbaf51521\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
              "      <td>No comment is expected from Barack Obama Membe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Did they post their votes for Hillary already?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
              "      <td>Now, most of the demonstrators gathered last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
              "      <td>A dozen politically active pastors came here f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
              "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47c96310-2bbe-4349-8101-00cdbaf51521')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47c96310-2bbe-4349-8101-00cdbaf51521 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47c96310-2bbe-4349-8101-00cdbaf51521');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "df.text.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGM5xu2Bgabx",
        "outputId": "8d7ab4b5-f975-4bc7-dce8-576a7aff7ba4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN and see class balance\n",
        "df = df[df['label'].notna()]\n",
        "df.groupby(['label']).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "VBtz7jqg-R-q",
        "outputId": "4d52db35-70d1-403a-c853-0029cec3e07e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0448a5ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.label[df.label == 0] = 'real'\n",
        "df.label[df.label == 1] = 'fake'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFP4H2DuWY62",
        "outputId": "3b5d45e8-9d96-4606-dfb7-c72bf940bf04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'real':0,'fake':1}\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['label']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "JP--7Z61-R8U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "2eL6vV7V-R6S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "    \n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "            total_TP_train = 0\n",
        "            total_FP_train = 0\n",
        "            total_FN_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                # Metrics calculation for training\n",
        "                TP = ((output.argmax(dim=1) == 1) & (train_label == 1)).sum()\n",
        "                FP = ((output.argmax(dim=1) == 1) & (train_label == 0)).sum()\n",
        "                FN = ((output.argmax(dim=1) == 0) & (train_label == 1)).sum()\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "\n",
        "                total_acc_train += acc\n",
        "                total_TP_train += TP\n",
        "                total_FP_train += FP\n",
        "                total_FN_train += FN\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "            total_TP_val = 0\n",
        "            total_FP_val = 0\n",
        "            total_FN_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    # Metrics calculation for validation\n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    TP = ((output.argmax(dim=1) == 1) & (val_label == 1)).sum()\n",
        "                    FP = ((output.argmax(dim=1) == 1) & (val_label == 0)).sum()\n",
        "                    FN = ((output.argmax(dim=1) == 0) & (val_label == 1)).sum()\n",
        "\n",
        "                    total_acc_val += acc\n",
        "                    total_TP_val += TP\n",
        "                    total_FP_val += FP\n",
        "                    total_FN_val += FN\n",
        "            \n",
        "            print(f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Train Precision: {total_TP_train / (total_TP_train + total_FP_train): .3f} | Train Recall: {total_TP_train / (total_TP_train + total_FN_train): .3f} | Train F1: {total_TP_train / (total_TP_train + 0.5*(total_FN_train+total_FP_train)): .3f}')\n",
        "            print(f'Epochs: {epoch_num + 1} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f} | Val Precision: {total_TP_val / (total_TP_val + total_FP_val): .3f} | Val Recall: {total_TP_val / (total_TP_val + total_FN_val): .3f} | Val F1: {total_TP_val / (total_TP_val + 0.5*(total_FN_val + total_FP_val)): .3f}')\n"
      ],
      "metadata": {
        "id": "Uc6Jur9N-R4Z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    total_TP_test = 0\n",
        "    total_FP_test = 0\n",
        "    total_FN_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              \n",
        "              # Metrics calculation for test\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              TP = ((output.argmax(dim=1) == 1) & (test_label == 1)).sum()\n",
        "              FP = ((output.argmax(dim=1) == 1) & (test_label == 0)).sum()\n",
        "              FN = ((output.argmax(dim=1) == 0) & (test_label == 1)).sum()\n",
        "\n",
        "              total_acc_test += acc\n",
        "              total_TP_test += TP\n",
        "              total_FP_test += FP\n",
        "              total_FN_test += FN\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f} | Test Precision: {total_TP_test / (total_TP_test + total_FP_test): .3f} | Test Recall: {total_TP_test / (total_TP_test + total_FN_test): .3f} | Test F1: {total_TP_test / (total_TP_test + 0.5*(total_FN_test + total_FP_test)): .3f}')\n"
      ],
      "metadata": {
        "id": "A4jWGtK_-R2F"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(115)\n",
        "\n",
        "# Check % splitting\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),[int(.7*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))\n",
        "print(len(df_train)/len(df),len(df_val)/len(df), len(df_test)/len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMRLuHl7-Rzu",
        "outputId": "69bb5a98-dfe3-404c-f8a0-d938c609dd83"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50493 14427 7214\n",
            "0.6999889095294868 0.2000027726176283 0.10000831785288491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrFwDseX-Rxo",
        "outputId": "26c944fb-3042-4d6b-af21-cfcc691e9673"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 25247/25247 [55:21<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.050 | Train Accuracy:  0.968 | Train Precision:  0.976 | Train Recall:  0.970 | Train F1:  0.973\n",
            "Epochs: 1 | Val Loss:  0.014 | Val Accuracy:  0.991 | Val Precision:  0.990 | Val Recall:  0.994 | Val F1:  0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25247/25247 [55:21<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.009 | Train Accuracy:  0.994 | Train Precision:  0.994 | Train Recall:  0.994 | Train F1:  0.994\n",
            "Epochs: 2 | Val Loss:  0.009 | Val Accuracy:  0.993 | Val Precision:  0.995 | Val Recall:  0.993 | Val F1:  0.994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25247/25247 [55:22<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.004 | Train Accuracy:  0.998 | Train Precision:  0.998 | Train Recall:  0.998 | Train F1:  0.998\n",
            "Epochs: 3 | Val Loss:  0.017 | Val Accuracy:  0.990 | Val Precision:  0.998 | Val Recall:  0.983 | Val F1:  0.990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25247/25247 [55:22<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.001 | Train Accuracy:  0.999 | Train Precision:  0.999 | Train Recall:  0.999 | Train F1:  0.999\n",
            "Epochs: 4 | Val Loss:  0.021 | Val Accuracy:  0.991 | Val Precision:  0.984 | Val Recall:  0.999 | Val F1:  0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25247/25247 [55:21<00:00,  7.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.001 | Train Accuracy:  0.999 | Train Precision:  0.999 | Train Recall:  1.000 | Train F1:  0.999\n",
            "Epochs: 5 | Val Loss:  0.012 | Val Accuracy:  0.994 | Val Precision:  0.992 | Val Recall:  0.997 | Val F1:  0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "kFs0kMr4-RvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf45446-d61c-44bc-8f09-e98ff2d1c6e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.994 | Test Precision:  0.992 | Test Recall:  0.996 | Test F1:  0.994\n"
          ]
        }
      ]
    }
  ]
}