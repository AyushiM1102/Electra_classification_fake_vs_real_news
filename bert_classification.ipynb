{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjrZSX4PLuo5ZSxFMEjrpD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiM1102/Electra_classification_fake_vs_real_news/blob/main/bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E4nAX4XR96s4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "D2AZCRrX-SCk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AyushiM1102/Electra_classification_fake_vs_real_news.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SRfNd4UhdHy",
        "outputId": "6f94e513-28a3-4d80-c91a-73dffde84f11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Electra_classification_fake_vs_real_news'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 52 (delta 9), reused 13 (delta 7), pack-reused 35\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip -d /content/Electra_classification_fake_vs_real_news/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU7HqRspetX5",
        "outputId": "675a1ba4-4646-4d0d-b388-1fa7c5ecdf2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Electra_classification_fake_vs_real_news/data/WELFake_Dataset.csv.zip\n",
            "  inflating: /content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv  \n",
            "  inflating: /content/Electra_classification_fake_vs_real_news/dataset/__MACOSX/._WELFake_Dataset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = f'/content/Electra_classification_fake_vs_real_news/dataset/WELFake_Dataset.csv'\n",
        "df = pd.read_csv(datapath)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tbYvbtie-SAh",
        "outputId": "876adc3e-cd01-46b1-f443-1db5c8447655"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
              "1           1                                                NaN   \n",
              "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
              "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
              "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
              "\n",
              "                                                text  label  \n",
              "0  No comment is expected from Barack Obama Membe...      1  \n",
              "1     Did they post their votes for Hillary already?      1  \n",
              "2   Now, most of the demonstrators gathered last ...      1  \n",
              "3  A dozen politically active pastors came here f...      0  \n",
              "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7bbd40f-dbac-4644-9311-2b43cbcfbeaa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
              "      <td>No comment is expected from Barack Obama Membe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Did they post their votes for Hillary already?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
              "      <td>Now, most of the demonstrators gathered last ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
              "      <td>A dozen politically active pastors came here f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
              "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7bbd40f-dbac-4644-9311-2b43cbcfbeaa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7bbd40f-dbac-4644-9311-2b43cbcfbeaa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7bbd40f-dbac-4644-9311-2b43cbcfbeaa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "df.text.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGM5xu2Bgabx",
        "outputId": "4d4e800b-e1ec-4f9c-fe1d-513f680da2de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop NaN and see class balance\n",
        "df = df[df['label'].notna()]\n",
        "df.groupby(['label']).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "VBtz7jqg-R-q",
        "outputId": "5870fe65-ea1a-4b9e-d6ad-5daf3da5a92e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdfbd741690>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.label[df.label == 0] = 'real'\n",
        "df.label[df.label == 1] = 'fake'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFP4H2DuWY62",
        "outputId": "07b20190-7950-4414-e97e-6bba670365ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'real':0,'fake':1}\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['label']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        print(self.texts[idx])\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "JP--7Z61-R8U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "2eL6vV7V-R6S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  "
      ],
      "metadata": {
        "id": "Uc6Jur9N-R4Z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              \n",
        "              # Accuracy\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "\n",
        "              # Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "\n",
        "              # Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "\n",
        "              # F1 = ((precision * recall)/(precision + recall))\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
      ],
      "metadata": {
        "id": "A4jWGtK_-R2F"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMRLuHl7-Rzu",
        "outputId": "a537c488-980a-44f1-dcaf-5c9f39eb2fab"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57707 7213 7214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrFwDseX-Rxo",
        "outputId": "9bc34ad5-3acb-4df3-a94d-6a2678485f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "kFs0kMr4-RvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}