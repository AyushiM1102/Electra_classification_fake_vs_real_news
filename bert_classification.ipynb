{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML0kJwA8lYsnsb+tZ57Um/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiM1102/Electra_classification_fake_vs_real_news/blob/main/bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E4nAX4XR96s4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "D2AZCRrX-SCk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = f'/content/train.csv'\n",
        "df = pd.read_csv(datapath)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tbYvbtie-SAh",
        "outputId": "a6a9d850-e833-4673-d181-3aee499ec2f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id                                              Tweet  following  \\\n",
              "0  10091  It's the everything else that's complicated. #...        0.0   \n",
              "1  10172  Eren sent a glare towards Mikasa then nodded a...        0.0   \n",
              "2   7012  I posted a new photo to Facebook http://fb.me/...        0.0   \n",
              "3   3697  #jan Idiot Chelsea Handler Diagnoses Trump Wit...     3319.0   \n",
              "4  10740  Pedophile Anthony Weiner is TERRIFIED of Getti...     4840.0   \n",
              "\n",
              "   followers  actions  is_retweet       location     Type  \n",
              "0    11500.0      NaN         0.0        Chicago  Quality  \n",
              "1        0.0      NaN         0.0            NaN  Quality  \n",
              "2        0.0      NaN         0.0  Scotland, U.K  Quality  \n",
              "3      611.0    294.0         0.0    Atlanta, Ga     Spam  \n",
              "4     1724.0   1522.0         0.0       Blumberg     Spam  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5836f4b-540a-46b9-a57c-0cda0b25ce6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>following</th>\n",
              "      <th>followers</th>\n",
              "      <th>actions</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>location</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10091</td>\n",
              "      <td>It's the everything else that's complicated. #...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10172</td>\n",
              "      <td>Eren sent a glare towards Mikasa then nodded a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7012</td>\n",
              "      <td>I posted a new photo to Facebook http://fb.me/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Scotland, U.K</td>\n",
              "      <td>Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3697</td>\n",
              "      <td>#jan Idiot Chelsea Handler Diagnoses Trump Wit...</td>\n",
              "      <td>3319.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Atlanta, Ga</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10740</td>\n",
              "      <td>Pedophile Anthony Weiner is TERRIFIED of Getti...</td>\n",
              "      <td>4840.0</td>\n",
              "      <td>1724.0</td>\n",
              "      <td>1522.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Blumberg</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5836f4b-540a-46b9-a57c-0cda0b25ce6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5836f4b-540a-46b9-a57c-0cda0b25ce6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5836f4b-540a-46b9-a57c-0cda0b25ce6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['is_retweet']).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "VBtz7jqg-R-q",
        "outputId": "d437d7d4-d94a-4049-8145-f7a807288bde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f601243f110>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'real':0,'spam':1}\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['is_retweet']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['Tweet']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "JP--7Z61-R8U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "2eL6vV7V-R6S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  "
      ],
      "metadata": {
        "id": "Uc6Jur9N-R4Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
      ],
      "metadata": {
        "id": "A4jWGtK_-R2F"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMRLuHl7-Rzu",
        "outputId": "225c3825-fecb-4fde-85ff-f540907e6dd8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9574 1197 1197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "WrFwDseX-Rxo",
        "outputId": "1b763039-0535-4974-8849-ee5c262e4354"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-51390cce2e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-b8b20ff16dff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1b835e5fd6ea>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_retweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         self.texts = [tokenizer(text, \n\u001b[1;32m     10\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1b835e5fd6ea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_retweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         self.texts = [tokenizer(text, \n\u001b[1;32m     10\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1.0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "kFs0kMr4-RvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}